{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI as Chat\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "temperature = float(os.getenv(\"OPENAI_TEMPERATURE\", 0))\n",
    "\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Chat(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Neo4j graph connection\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "# Initialize Neo4j vector store connection\n",
    "vector_store = Neo4jVector(\n",
    "    embeddings,\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "print(graph)\n",
    "print()\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (row) { ... }} {position: line: 1, column: 21, offset: 20} for query: \"UNWIND $data AS row CALL { WITH row MERGE (c:`Chunk` {id: row.id}) WITH c, row CALL db.create.setNodeVectorProperty(c, 'embedding', row.embedding) SET c.`text` = row.text SET c += row.metadata } IN TRANSACTIONS OF 1000 ROWS \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.neo4j_vector.Neo4jVector object at 0x1215404a0>\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a method to retrieve documents from the graph\n",
    "# Replace with the actual query to retrieve documents\n",
    "documents = graph.query(\"MATCH (n) RETURN n LIMIT 25;\")\n",
    "\n",
    "# Convert the retrieved documents into Document objects\n",
    "document_objects = [Document(page_content=str(doc)) for doc in documents]\n",
    "\n",
    "db = Neo4jVector.from_documents(\n",
    "    document_objects, embeddings, url=NEO4J_URL, username=NEO4J_USERNAME, password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11706c080>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11706dca0>, root_client=<openai.OpenAI object at 0x116e6afc0>, root_async_client=<openai.AsyncOpenAI object at 0x10582fec0>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='Context:\\n{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['Neo4jVector', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.neo4j_vector.Neo4jVector object at 0x1215404a0>, search_kwargs={})\n"
     ]
    }
   ],
   "source": [
    "stack_retriever = RetrievalQA.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "print(stack_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = stack_retriever.invoke(\"what is in the db?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database contains questions and discussions related to technical issues and programming, specifically focusing on topics like Neo4j, encryption in Node.js, and connection strings for databases. The entries include questions about migrating data from RDBMS to Neo4j, specifying database names in connection strings for Neo4j, handling deprecated encryption methods in Node.js, and storing credentials in connection strings for Neo4j.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is in the db?',\n",
       " 'result': 'The database contains questions and discussions related to technical issues and programming, specifically focusing on topics like Neo4j, encryption in Node.js, and connection strings for databases. The entries include questions about migrating data from RDBMS to Neo4j, specifying database names in connection strings for Neo4j, handling deprecated encryption methods in Node.js, and storing credentials in connection strings for Neo4j.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
