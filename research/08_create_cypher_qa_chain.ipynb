{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI as Chat\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "temperature = float(os.getenv(\"OPENAI_TEMPERATURE\", 0))\n",
    "\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Chat(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cypher generation template\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question', 'schema'] input_types={} partial_variables={} template=\"\\nYou are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\\nConvert the user's question based on the schema.\\n\\nSchema: {schema}\\nQuestion: {question}\\n\"\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template for Cypher generation\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "print(cypher_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x111f57110> cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template=\"\\nYou are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\\nConvert the user's question based on the schema.\\n\\nSchema: {schema}\\nQuestion: {question}\\n\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111fa47d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x111fa6420>, root_client=<openai.OpenAI object at 0x110db01d0>, root_async_client=<openai.AsyncOpenAI object at 0x111fa4830>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}) qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111fa47d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x111fa6420>, root_client=<openai.OpenAI object at 0x110db01d0>, root_async_client=<openai.AsyncOpenAI object at 0x111fa4830>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}) graph_schema='Node properties are the following:\\nSession {id: STRING},Message {type: STRING, content: STRING},Chunk {id: STRING, embedding: LIST, text: STRING, source: STRING},Person {embedding: LIST, name: STRING, location: STRING, age: INTEGER, hobby: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Session)-[:LAST_MESSAGE]->(:Message),(:Message)-[:NEXT]->(:Message)' allow_dangerous_requests=True\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GraphCypherQAChain with the language model, graph, and prompt template\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "print(cypher_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (n)\n",
      "RETURN labels(n) AS NodeType, properties(n) AS NodeProperties\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'NodeType': ['Session'], 'NodeProperties': {'id': 'aee31963-d525-4cfb-9b71-f9dae62a1ccf'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': 'hi', 'type': 'human'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': \"Hey dude! What's up? You ready to catch some gnarly waves today? üåäü§ô\", 'type': 'ai'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': 'how is watergate?', 'type': 'human'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': \"Ah, Watergate Bay, bro! It's looking like a chill sesh today with 3ft waves and some onshore winds. Not the most epic conditions, but you can still have a fun time shredding those smaller sets. Just keep it mellow and enjoy the ride, man! üèÑ\\u200d‚ôÇÔ∏èüåä\", 'type': 'ai'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': '', 'type': 'human'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': \"Hey, you still there, dude? If you're thinking about hitting up another spot or need some tips, just let me know! ü§ôüåä\", 'type': 'ai'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': '', 'type': 'human'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': 'No worries, bro! Just let me know if you wanna chat about the surf or anything else. Catch ya later, and keep those vibes high! ü§ôüåä', 'type': 'ai'}}, {'NodeType': ['Message'], 'NodeProperties': {'content': '', 'type': 'human'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with a sample query and print the result\n",
    "response = cypher_chain.invoke(\n",
    "    {\"query\": \"Give info about each node in the graph\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph contains the following nodes:\n",
      "\n",
      "1. A Session node with the ID: aee31963-d525-4cfb-9b71-f9dae62a1ccf.\n",
      "2. A Message node with the content: \"hi\" and type: human.\n",
      "3. A Message node with the content: \"Hey dude! What's up? You ready to catch some gnarly waves today? üåäü§ô\" and type: ai.\n",
      "4. A Message node with the content: \"how is watergate?\" and type: human.\n",
      "5. A Message node with the content: \"Ah, Watergate Bay, bro! It's looking like a chill sesh today with 3ft waves and some onshore winds. Not the most epic conditions, but you can still have a fun time shredding those smaller sets. Just keep it mellow and enjoy the ride, man! üèÑ‚Äç‚ôÇÔ∏èüåä\" and type: ai.\n",
      "6. A Message node with an empty content and type: human.\n",
      "7. A Message node with the content: \"Hey, you still there, dude? If you're thinking about hitting up another spot or need some tips, just let me know! ü§ôüåä\" and type: ai.\n",
      "8. A Message node with an empty content and type: human.\n",
      "9. A Message node with the content: \"No worries, bro! Just let me know if you wanna chat about the surf or anything else. Catch ya later, and keep those vibes high! ü§ôüåä\" and type: ai.\n",
      "10. A Message node with an empty content and type: human.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
