{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import Neo4jChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_type=os.getenv(\"AZURE_OPENAI_API_TYPE\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VER\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm2.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = response.response_metadata\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve environment variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize Neo4j graph connection\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique session ID\n",
    "SESSION_ID = str(uuid4())\n",
    "print(f\"Session ID: {SESSION_ID}\")\n",
    "\n",
    "\n",
    "def get_memory(session_id):\n",
    "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(chat_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = \"\"\"\n",
    "(Movie)-[:IN_GENRE]->(Genre), (Movie)-[:DIRECTED_BY]->(Director), \n",
    "(Movie)-[:HAS_ACTOR]->(Actor), (Movie)-[:HAS_RATING]->(Rating)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = f\"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, For example \"The 39 Steps\" becomes \"39 Steps, The\" or \"The Matrix\" becomes \"Matrix, The\".\n",
    "\n",
    "If no data is returned, do not attempt to answer the question.\n",
    "Only respond to questions that require you to construct a Cypher statement.\n",
    "Do not include any explanations or apologies in your responses.\n",
    "\n",
    "Schema: {SCHEMA}\n",
    "Question: {{question}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_example = \"\"\"\n",
    "Find all movies directed by Christopher Nolan\n",
    "MATCH (m:Movie)-[:DIRECTED_BY]->(d:Director {name: 'Christopher Nolan'})\n",
    "RETURN m.title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert in movies and Neo4j queries.\"),\n",
    "    (\"system\", \"{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chat chain with the message history and the output parser\n",
    "chat_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "print(chat_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with message history integration\n",
    "chat_with_message_history = RunnableWithMessageHistory(\n",
    "    chat_chain,\n",
    "    get_memory,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "print(chat_with_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Find all movies directed by James Cameron\"\n",
    "\n",
    "response = chat_with_message_history.invoke(\n",
    "    {\n",
    "        \"context\": \"You are an expert in movies and Neo4j queries.\",\n",
    "        \"question\": question,\n",
    "    },\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": SESSION_ID}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
